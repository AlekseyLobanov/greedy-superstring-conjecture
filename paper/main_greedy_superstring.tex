\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath, amsfonts, amssymb, amsthm}

\usepackage{setspace}
\usepackage{relsize}
\usepackage{latexsym}
\usepackage{enumitem}

\usepackage{tikz}
\usetikzlibrary{calc,arrows,shapes,backgrounds,patterns,fit,decorations,decorations.pathmorphing}

\usepackage[colorinlistoftodos]{todonotes}
\usepackage[hidelinks]{hyperref}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{claim}{Claim}
\newtheorem{definition}{Definition}
\newtheorem*{statement}{Statement}
\newtheorem*{remark}{Remark}


\DeclareMathOperator{\overlap}{overlap}
\DeclareMathOperator{\pref}{pref}
\DeclareMathOperator{\prefix}{prefix}
\DeclareMathOperator{\suff}{suff}
\DeclareMathOperator{\ein}{in}
\DeclareMathOperator{\eout}{out}
\DeclareMathOperator{\bal}{\Delta}
\DeclareMathOperator{\lvl}{level}
\DeclareMathOperator{\defn}{def}

\renewcommand{\geq}{\geqslant}
\renewcommand{\leq}{\leqslant}
\newcommand{\sedge}[2]{$({\tt #1} \to {\tt #2})$}
\newcommand{\cld}{D_{cl}}
\newcommand{\grd}{D_{gr}}
\newcommand{\cldr}[1]{D_{cl}(#1)}
\newcommand{\grdr}[1]{D_{gr}(#1)}
\newcommand{\clgraph}{G_{cl}}
\newcommand{\grgraph}{G_{gr}}


\tikzstyle{hgedge}=[->,gray!30!white]
\tikzstyle{anypath}=[->,dashed]
\tikzstyle{vertex}=[draw,ellipse,inner sep=0.5mm]
\tikzstyle{inputvertex}=[draw,rectangle,inner sep=0.5mm]

\newenvironment{mypic}{\begin{center}\begin{tikzpicture}[>=latex,line width=.3mm]}{\end{tikzpicture}\end{center}}


\begin{document}
%\hrule
%\input pics

\sloppy
\date{}
\title{Collapsing Superstring Conjecture}
\author{}
%\author{
%Alexander Golovnev\thanks{Harvard University.}
%\and
%Alexander~S.~Kulikov\thanks{Steklov Institute of Mathematics at St. Petersburg, Russian Academy of Sciences.}
%\and
%Alexander Logunov\footnotemark[2]
%\and
%Ivan Mihajlin\thanks{University of California San Diego.}
%}
\maketitle

\begin{abstract}
In the Shortest Common Superstring (SCS) problem, one is given a collection of strings, and needs to find a shortest string containing each of them as a substring. SCS admits $2\frac{11}{23}$- and $2\frac{11}{30}$-approximations in polynomial time. While these approximation algorithms and their analyzes are technically involved, the $30$ years old Greedy Conjecture claims that the trivial and efficient Greedy Algorithm gives a $2$-approximation for SCS. The Greedy Algorithm repeatedly merges two strings with the largest intersection into one, until only one string remains.

We develop a graph-theoretic framework for studying approximation algorithms for SCS. In this framework, we give a (stronger) counterpart to the Greedy Conjecture: We conjecture that the presented in this paper Greedy Hierarchical Algorithm gives a $2$-approximation for SCS. This algorithm is almost as simple as the standard Greedy Algorithm, and we suggest a combinatorial approach for proving this conjecture. We advocate the conjecture by showing that the Greedy Hierarchical Algorithm gives a $2$-approximation in the case where all input strings have length at most $3$ (which until recently had been the only case where the Greedy Conjecture was proven). We also tested our conjecture on tens of thousands of instances of SCS.

Except for its conjectured good approximation ratio, the Greedy Hierarchical Algorithm finds \emph{exact} solutions for the special cases where we know polynomial-time (not greedy) exact algorithms: (1) when the input strings form a spectrum of a string (2) when all input string have length at most $2$.
\end{abstract}

%\tableofcontents

\section{Introduction}
The {\em shortest common superstring problem} (abbreviated as SCS) is:
given a~set of strings, find a~shortest string that contains all of them as
substrings. This problems finds applications in genome assembly~\cite{waterman1995introduction, pevzner2001eulerian}, and data compression~\cite{GMS1980, phdthesis, storer1987data} (see \cite{gevezes2014shortest, mucha2007tutorial} for an overview of SCS, its applications and algorithms).  SCS is known to be $\mathbf{NP}$-hard~\cite{GMS1980} and even $\mathbf{MAX}$-$\mathbf{SNP}$-hard~\cite{BJLTY1991}, but it admits constant-factor approximation in polynomial time.

The recent breakthrough results by Mucha~\cite{M2013} and Paluch~\cite{P14} give polynomial-time $2\frac{11}{23}$- and $2\frac{11}{30}$-approximations for SCS (see \cite[Section~2.1]{GKM13} for an overview of the 
previously known approximation algorithms
and inapproximability results). While these approximation algorithms use an algorithm for Maximum Weight Perfect Matching as a subroutine, the $30$ years old Greedy Conjecture~\cite{storer1987data, TU1988, T1989, BJLTY1991} claims that the trivial Greedy Algorithm whose pseudocode is given in Algorithm~\ref{algo:ga} is 2-approximate.



The known approximation algorithms (including the Greedy Algorithm) estimate the approximation ratio via the overlap graph. Since our current knowledge of the overlap graph properties is provably not sufficient for showing strong approximation factors, these algorithms also separately take into account string properties. The goal of this paper is to develop a simple combinatorial framework which captures all features of the input strings needed for proving approximation ratios of algorithms.

\todo[inline]{Sasha, mention our paper with Savinov and the paper by Rivals}

\begin{algorithm}[ht]
\label{algo:ga}
\caption{Greedy Algorithm (GA)}
\hspace*{\algorithmicindent} \textbf{Input:} set of strings~${\cal S}$.\\
\hspace*{\algorithmicindent} \textbf{Output:} a~superstring~for $\mathcal{S}$.
\begin{algorithmic}[1]
\While{$\mathcal{S}$ contains at least two strings}
\State extract from $\mathcal{S}$ two strings with the maximum overlap
\State add to $\mathcal{S}$ the shortest superstring of these two strings
\EndWhile
\State return the only string from $\mathcal{S}$
\end{algorithmic}
\end{algorithm}



%following simple 
%greedy algorithm is 2-approximate: while there are more than two strings 
%in the set, take two of them with the maximum overlap and replace them
%with their shortest superstring.

Most of the approaches for approximating SCS are based on the
{\em overlap graph}: it has input strings as nodes, any two nodes 
are joined by an~edge of weight equal to their overlap.  
While it is a~convenient graph structure, it does not seem to be sufficient
for proving the greedy conjecture.
\todo[inline]{Sasha, review mouse approaches}

In this paper, we continue the study of the so-called {\em hierarchical graph}
introduced by Golovnev et al.~\cite{scs_exact}. This graph in a~sense generalizes de~Bruijn graph and is designed specifically 
for the SCS problem and contains more useful information about input strings
than just all pairwise overlaps. We present a simple and natural greedy algorithm
on the hierarchical graph. 
We demonstrate its usefulness by showing that it finds an optimal solution 
in two well-known polynomially solvable special cases: strings of length~2 and
a~$k$-spectrum of a~string.

We then conjecture that this greedy algorithm is 2-approximate. For this, we introduce an {\em even stronger} conjecture that we call 
{\em Collapsing Superstring Conjecture}. 
Roughly, it says that it is possible to transform a~doubled optimal 
solution into a~greedy solution. 
The corresponding transformation, that we call {\em collapsing}, 
is just replacing two edges $a\alpha \to a\alpha b \to \alpha b$ 
by two edges $a\alpha \to \alpha \to \alpha b$ (where $\alpha$ is an arbitrary string). 
We report on computational experiments that verified the 
conjecture on many datasets (both hand-crafted and generated randomly
according to various distributions). 
We then support the Collapsing Superstring Conjecture by 
proving that it holds for the~special case when the input strings have length~3.

The Collapsing Superstring Conjecture immediately implies that the Greedy
Hierarchical Algorithm is 2-approximate. Surprisingly, it seems to be much
stronger in the following sense. Let $GS$ be the set of edges of a~greedy
solution and let $DOS$ be the set of edges of a~collapsed doubled optimal
solution. For proving 2-approximability, it suffices to show that $|GS| \le |DOS|$. 
One way of showing this is to prove that $GS \subseteq DOS$. 
The conjecture, at the same time, states that this inclusion holds with equality.

We implemented the Greedy Hierarchical Algorithm~\cite{github}. We tested it on tens of thousands of examples, and did not find counterexamples for our conjectures. We provide a web interface~\cite{webpage} so that anyone could test the conjectures on arbitrary datasets. The webpage visualizes how the Hierarchical Greedy and Collapsing algorithms work.

\section{Definitions}
\subsection{Shortest Common Superstring Problem}
%By $u\sqsupset v$ ($u\sqsubset v$) we denote that $u$ is a suffix (prefix) of $v$.
For strings~$s$ and~$t$, by $\overlap(s,t)$
we denote the longest suffix of~$s$ that is also 
a~prefix of~$t$. By $\pref(s,t)$
we denote the first $|s|-|\overlap(s,t)|$ symbols of $s$.
Similarly, $\suff(s,t)$ is the last
$|t|-|\overlap(s,t)|$ symbols of~$t$. 
By $\pref(s)$ and $\suff(s)$ we denote, respectively,
the first and the last $|s|-1$ symbols of~$s$. See Fig.~\ref{fig:overlap} for a~visual explanation.
The empty string is denoted by $\varepsilon$.

\begin{figure}[ht]
\begin{mypic}
\begin{scope}
%\draw[help lines,step=5mm] (0,0) grid (14,3);

\draw (0,2) rectangle (6,2.5);
\draw[step=5mm] (0,2) grid (6,2.5);
\node[left] at (0,2.25) {$s$};
\draw (3,0.5) rectangle (10,1);
\draw[step=5mm] (3,0.5) grid (10,1);
\node[right] at (10,0.75) {$t$};

\foreach \x in {3.25, 3.75, ..., 5.75}
  \draw[gray,thick] (\x,2) -- (\x,1);

\foreach \f/\t/\y/\lab in {0/3/1.5/{\pref(s,t)}, 
3/6/0/{\overlap(s,t)}, 6/10/0/{\suff(s,t)}, 0/5.5/3/\pref(s),
0.5/6/3.5/\suff(s)}
  \path (\f,\y) edge[<->] node[rectangle,inner sep=0.5mm,fill=white] {\strut $\lab$} (\t,\y);
  
\foreach \x/\a in {0/b, 0.5/a, 1/a, 1.5/c, 2/a, 2.5/b, 3/b, 3.5/c, 4/a, 4.5/a, 5/c, 5.5/b}
  \node at (\x+0.25,2.25) {\tt \a};
\foreach \x/\a in {3/b, 3.5/c, 4/a, 4.5/a, 5/c, 5.5/b, 6/a, 6.5/c, 7/a, 7.5/a, 8/a, 8.5/b, 9/c, 9.5/a}
  \node at (\x+0.25,0.75) {\tt \a};
\end{scope}
\end{mypic}
\caption{Pictorial explanations of $\pref$, $\suff$, and $\overlap$ functions.}
\label{fig:overlap}
\end{figure}


Throughout the paper by ${\cal S}=\{s_1, \dots, s_n\}$ we denote
a~set of~$n$ input strings. We assume that no input string is a~substring of another (such a~substring can be removed from $\mathcal{S}$ on the preprocessing stage). Note that SCS is a~{\em permutation problem}: to find a~shortest string containing all $s_i$'s in a given order one just
overlaps the strings in this order, see Fig.~\ref{fig:permutation}. This simple observation makes many connections to other permutation problems, including different versions of the traveling salesman problem.

\begin{figure}[ht]
\begin{mypic}
%\draw[help lines] (0,0) grid (16,4);

\foreach \x in {0, 2.5, 5.5, 10, 12.5, 16}
  \draw[dashed,gray,thin] (\x,-0.5) -- (\x,4);

\foreach \x/\y/\len/\label in {0/3/5/s_{i_1}, 1/2.5/9/s_{i_2}, 2/2/16/s_{i_3}, 10.5/1/4/s_{i_{n-1}}, 12/0.5/8/s_{i_n}} {
  \draw (\x,\y) rectangle (\x+0.5*\len,\y+0.5);
  \node at (\x+0.25*\len,\y+0.25) {$\label$};
}

\foreach \f/\t/\label in {0/2.5/{s_{i_1}}, 2.5/5.5/{\suff(s_{i_1}, s_{i_2})}, 5.5/10/{\suff(s_{i_2}, s_{i_3})}, 12.5/16/{\suff(s_{i_{n-1}}, s_{i_n})}}
  \path (\f,0) edge[<->] node[rectangle,inner sep=0.5mm,fill=white] {\strut $\label$} (\t,0);

\node at (11,0) {$\dotsb$};
\node at (10.5,1.75) {$\dotsb$};
\end{mypic}
\caption{SCS is a~permutation problem. The length of a~superstring corresponding to a~permutation $(s_{i_1}, \dotsc, s_{i_n})$ is $|s_{i_1}|$ plus the sum of the lengths of suffixes of consecutive pairs of strings.}
\label{fig:permutation}
\end{figure}


\subsection{Hierarchical Graph}
%\begin{definition}[hierarchical graph]
For a~set of string~${\cal S}$, a~\emph{hierarchical graph} $HG=(V,E)$ is a~weighted directed graph with $V=\{v \colon \text{$v$ is a~substring of some $s \in {\cal S}$}\}$. For every $v \in V$ with $v \neq \varepsilon$, the set of edges~$E$ contains an {\em up-edge} $(\pref(v), v)$ of weight~1 and a {\em down-edge} $(v, \suff(v))$ of weight~0. The physical meaning of an up-edge is appending one symbol to the end of the current string (and that is why it has weight~1), whereas the physical meaning of the down-edge is cutting down one symbol from the beginning of the current string.
%\end{definition}
%
Figure~\ref{fig:hgex}(a) gives an example of the hierarchical graph as well as shows that the terminology of up- and down-edges comes from placing all the strings of the same length at the same layer where the $i$-th layer contains strings of length~$i$. 
%\todo[inline]{Sasha, the following graph is wrong! It does not contain the node {\tt bc} (I took from another paper where we used a~different version of the hierarchical graph). Come up with a different example. On the left show the graph. On the right show, say, a solution in this graph.}


\newcommand{\we}[4]{
\begin{scope}[xshift=#1mm,yshift=#2mm]
\foreach \n/\x/\y in {aaa/0/3, cae/1/3, aec/3/3, eee/4/3}
  \node[inputvertex] (\n) at (\x,\y) {\tt \n};
%  
\foreach \n/\x/\y in {aa/0/2, ca/1/2, ae/2/2, ec/3/2, ee/4/2, a/1/1, c/2/1, e/3/1}
  \node[vertex] (\n) at (\x,\y) {\tt \n};
%
\node[vertex] (eps) at (2,0) {$\varepsilon$};
%
\foreach \f/\t/\a in {eps/e/10, e/eps/10, eps/c/10, c/eps/10, eps/a/10, a/eps/10, a/aa/10, aa/a/10, aa/aaa/10, aaa/aa/10, c/ca/0, ca/cae/0, cae/ae/0, ae/aec/0, aec/ec/0, ee/eee/10, eee/ee/10, e/ee/10, ee/e/10, ca/a/0, a/ae/0, ae/e/0, e/ec/0, ec/c/0}
  \path (\f) edge[hgedge,bend left=\a] (\t);
  
\node at (2,-1) {(#3)};

#4
\end{scope}
}

\begin{figure}[ht]
\begin{mypic}
\we{0}{0}{a}{}

\we{57}{0}{b}{
\foreach \f/\t/\a in {eps/a/10, a/ae/0, ae/aec/0, aec/ec/0, ec/c/0, c/ca/0, ca/a/0, a/eps/10}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{114}{0}{c}{
\foreach \f/\t/\a in {eps/a/10, a/aa/10, aa/aaa/10, aaa/aa/10, aa/a/10, a/ae/0, ae/aec/0, aec/ec/0, ec/c/0, c/ca/0, ca/cae/0, cae/ae/0, ae/e/0, e/ee/10, ee/eee/10, eee/ee/10, ee/e/10, e/eps/10}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}
\end{mypic}
\caption{(a)~Hierarchical graph for a~dataset $\mathcal{S}=\{{\tt aaa}, {\tt cae}, {\tt aec}, {\tt eee}\}$. (b)~A~walk $\varepsilon \to {\tt a} \to {\tt ae} \to {\tt aec} \to {\tt ec} \to {\tt c} \to {\tt ca} \to {\tt a} \to \varepsilon$ has length (or weight)~4 and spells a~string {\tt aeca} of length~4. (c)~An~optimal superstring for~$\mathcal{S}$ is {\tt aaaecaeee}. It has length~9, corresponds to a~permutation $({\tt aaa}, {\tt aec}, {\tt cae}, {\tt eee})$, and defines a~walk of length~9 shown in black.}
\label{fig:hgex}
\end{figure}

What we are looking for in this graph is a shortest
walk from $\varepsilon$ to $\varepsilon$ going
through all the nodes from~$\mathcal{S}$.
It is not difficult to see that the length of a~walk 
from $\varepsilon$ to $\varepsilon$ equals the 
length of the string spelled by this walk. 
This is just because each up-edge has 
weight~$1$ and adds one symbol to 
the current string. See Figure~\ref{fig:hgex}(b) for an~example.
%For example, in the graph of Fig.~\ref{fig:hgexfirst} 
%a~walk $\varepsilon\to{\tt b}\to{\tt ba}
%\to{\tt bab}\to{\tt ab}\to{\tt abc}
%\to{\tt abca}\to{\tt bca}\to{\tt ca}\to{\tt a}
%\to\varepsilon$ has length $5$ and spells 
%a~string {\tt babca} 
%of length~$5$ in a~natural way.\todo{Update this when you update the figure.}

Hence, what we are looking for in this graph is a~shortest closed walk from $\varepsilon$ to $\varepsilon$ that visits all nodes from~${\cal S}$. By saying a~walk here we mean that it may contain repeated nodes and edges. Note that the multiset of edges of such a~walk must be Eulerian. It will prove convenient to define a~{\em solution} in hierarchical graph as an~Eulerian multiset of edges~$D$ that goes through $\varepsilon$ and all nodes from~${\cal S}$. Given such a~solution~$D$, one can easily recover an Eulerian cycle (that might not be unique). This cycle spells a~superstring of~${\cal S}$ of the same length as~$D$. Figure~\ref{fig:hgex}(c) shows a~solution corresponding to an optimal superstring.

\section{Greedy Hierarchical Algorithm}
\subsection{Algorithm and Conjecture}
In this section, we present a~greedy algorithm for
finding a~superstring in the hierarchical graph. 
It constructs a~solution~$D$ in a~stingy fashion. 
Namely, the algorithm only add edges to~$D$ 
if it is absolutely necessary: either to balance the degree of a~node or to ensure connectivity 
(as $D$ must be Eulerian). 
More precisely, it starts from considering the input
strings~${\cal S}$. Since we assume that 
no $s \in {\cal S}$ is a~substring of another 
$t \in {\cal S}$, there is no down-path from~$t$ to~$s$ in $HG_{\cal S}$. 
This means that any walk through $\varepsilon$ and ${\cal S}$ goes through edges $\{(\operatorname{pref}(s), s), (s, \operatorname{suf}(s)) \colon s \in {\cal S}\}$. The algorithm adds all of them to~$D$ and starts processing all the nodes level by level, from top to bottom. On each level, we process the nodes in the lexicographic order. If the degree of the current node~$v$ is imbalanced, we balance it by adding an appropriate number of incoming (i.e., $(\pref(v),v)$) or outgoing (i.e., $(v, \suff(v))$) edges from the previous level. In case $v$ is balanced, we just skip it. The only exception when we do not skip it is when {\em $v$~lies in an Eulerian component and $v$ is the last chance of this component to be connected to the rest of the edges in~$D$}. We give an~example of such a~situation below. The pseudocode is given in~Algorithm~\ref{algo:gha}. Figure~\ref{fig:hgexa} shows a~few intermediate stages of the algorithm on our working sample dataset.


\begin{algorithm}[ht]
\label{algo:gha}
\caption{Greedy Hierarchical Algorithm (GHA)}
\hspace*{\algorithmicindent} \textbf{Input:} set of strings~${\cal S}$.\\
\hspace*{\algorithmicindent} \textbf{Output:} solution~$D$.
\begin{algorithmic}[1]
\State $HG(V,E) \gets \text{hierarchical graph of ${\cal S}$}$ 
\State $D \gets \{(\operatorname{pref}(s), s), (s, \operatorname{suf}(s)) \colon s \in {\cal S}\}$
\For{level $l$ from $\max\{|s| \colon s \in {\cal S}\}$ downto 1}
\For{node $v \in V$ with $|v|=l$ in the lexicographic order}
\If{$\operatorname{upper-indegree}(v, D) \neq \operatorname{upper-outdegree}(v, D)$}
\State balance the total degree of $v$ in $E$ by adding an appropriate number of lower edges
\Else
\State ${\cal C} \gets \text{weakly connected component of $v$ in $D$}$
\State $u \gets \text{the lexicographically largest string among shortest strings in ${\cal C}$}$
\If{${\cal C}$ is Eulerian, $\varepsilon \not \in {\cal C}$, and $v = u$}
\State $D \gets D \cup \{(\pref(v), v), (v, \suff(v))\}$
\EndIf
\EndIf
\EndFor
\EndFor
\State return $D$
\end{algorithmic}
\end{algorithm}

\begin{figure}[ht]
\begin{mypic}
\we{0}{0}{a}{
\foreach \f/\t/\a in {aa/aaa/10, aaa/aa/10, ca/cae/0, cae/ae/0, ae/aec/0, aec/ec/0, ee/eee/10, eee/ee/10}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{57}{0}{b}{
\foreach \f/\t/\a in {aa/aaa/10, aaa/aa/10, ca/cae/0, cae/ae/0, ae/aec/0, aec/ec/0, ee/eee/10, eee/ee/10, aa/a/10, a/aa/10, c/ca/0, ec/c/0, ee/e/10, e/ee/10}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{114}{0}{c}{
\foreach \f/\t/\a in {aa/aaa/10, aaa/aa/10, ca/cae/0, cae/ae/0, ae/aec/0, aec/ec/0, ee/eee/10, eee/ee/10, aa/a/10, a/aa/10, c/ca/0, ec/c/0, ee/e/10, e/ee/10, a/aa/10, aa/a/10, eps/c/10, c/eps/10, e/eps/10, eps/e/10, a/eps/10, eps/a/10}
\path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}
\end{mypic}
\caption{(a)~After processing the $l=3$ level. (b)~After processing the $l=2$ level. Note that for the node {\tt aa} we add two lower edges ($({\tt a}, {\tt aa})$ and $({\tt aa}, {\tt a})$) since otherwise the corresponding weakly connected component ($\{{\tt aa}, {\tt aaa}\}$) will not be connected to the rest of the solution. At the same time, when processing the node {\tt ae} we observe that it lies in a~weakly connected component that contain imbalanced nodes ({\tt ca} and {\tt ec}), hence there is no need to add two lower edges to {\tt ae}. (c)~After processing the $l=1$ level. The resulting solution has length~10 and is therefore suboptimal.}
\label{fig:hgexa}
\end{figure}

The advantage of GHA over GA is that GHA is more flexible in the following sense. On every step, GA selects two strings and fixes tightly an order on them. GHA instead works to ensure connectivity. When the resulting set~$D$ is connected, an actual order of input strings will be given by the corresponding Eulerian cycle through~$D$.

We are now ready to state the main conjecture of this paper.
\newtheorem*{ghcc}{Greedy Hierarchical Superstring Conjecture}
\begin{ghcc}
GHA is 2-approximate.
\end{ghcc}
In the rest of this section, we show the behavior of GHA on various datasets. In particular, we prove that GHA solves optimally two well-known polynomialy solvable special cases of SCS. In the next section, we suggest a~way of proving the conjecture by connecting GHA to another algorithm.


\subsection{Strings of Length~2}
\todo[inline]{Sasha, please write}

\subsection{Spectrum of a~String}
By a~$k$-spectrum of a~string $s$ 
(of length at least~$k$)
we call a~set of all substrings of~$s$ of length~$k$.

\begin{lemma}
Let ${\cal S}$ be a~$k$-spectrum of an unknown string~$s$. Then $GHA({\cal S})$ returns a~superstring of length at most~$|s|$. 
\end{lemma}
\todo[inline]{Sasha, please write this subsection}

\subsection{Tough Dataset}
There is a~well-known dataset consisting of just three strings where the classical greedy algorithm produces a~superstring that is almost twice longer than an optimal one: $s_1={\tt cc}({\tt ae})^n$, $s_2=({\tt ea})^{n+1}$, $s_3=({\tt ae})^n{\tt cc}$. Since $\overlap(s_1, s_3)=2n$,
 while $\overlap(s_1,s_2)=\overlap(s_2,s_3)=2n-1$, the greedy algorithm produces a~permutation $(s_1, s_3, s_2)$ (or $(s_2,s_1,s_3)$). I.e., by greedily taking the massive overlap of length $2n$ it loses the possibility to insert $s_2$ between $s_1$ and $s_3$ and to get two overlaps of size $2n-1$. The resulting superstring has length $4n+6$. At the same time, the optimal superstring corresponds to a~permutation $(s_1,s_2,s_3)$ and has length $2n+8$.
 
The algorithm GHA makes a~similar mistake on this dataset, see Figure~\ref{fig:tough}. When processing the node $({\tt ea})^n$, GHA does not add two lower edges to it and misses a~chance to connect two components. It is then forced to connect these two components through~$\varepsilon$.

%\newcommand{\ged}[3]{
%\begin{scope}[xshift=#1mm]
%\foreach \n/\x/\y in {ccae/0.625/4, aecc/3.125/4, eaea/5.625/4}
%  \node[inputvertex] (\n) at (\x,\y) {\tt \n};
%\foreach \n/\x/\y in {cca/0/3, cae/1.25/3, aec/2.5/3, ecc/3.75/3, eae/5/3, aea/6.25/3, cc/1.5/2, ca/2.5/2, ae/3.5/2, ec/4.5/2, ea/5.5/2, c/2.5/1, a/3.5/1, e/4.5/1}
%  \node[vertex] (\n) at (\x,\y) {\tt \n};
%\node[vertex] (eps) at (3.5,0) {$\varepsilon$};
%\node at (3.5,-1) {(#2)};
%
%\foreach \f/\t/\a in {eps/c/10, c/eps/10, eps/a/10, a/eps/10, eps/e/10, e/eps/10, c/cc/10, cc/c/10, c/ca/0, ca/a/0, a/ae/0, ae/e/0, e/ec/0, ec/c/0, e/ea/0, ea/a/0, cc/cca/0, cca/ca/0, ca/cae/0, cae/ae/0, ae/aec/0, aec/ec/0, ec/ecc/0, ecc/cc/0, ea/eae/0, eae/ae/0, ae/aea/0, aea/ea/0, cca/ccae/0, ccae/cae/0, aec/aecc/0, aecc/ecc/0, eae/eaea/0, eaea/aea/0}
%  \path (\f) edge[hgedge,bend left=\a] (\t);
%
%#3
%\end{scope}
%}
% 
%\begin{figure}
%\begin{mypic}
%\ged{0}{a}{
%\foreach \f/\t/\a in {eps/c/10, c/cc/10, cc/cca/0, cca/ccae/0, ccae/cae/0, cae/ae/0, ae/e/0, e/ea/0, ea/eae/0, eae/eaea/0, eaea/aea/0, aea/ea/0, ea/a/0, a/ae/0, ae/aec/0, aec/aecc/0, aecc/ecc/0, ecc/cc/0, cc/c/10, c/eps/10}
%  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
%}
%
%\ged{80}{b}{}
%\end{mypic}
%\caption{(a)~A~solution of length~10 corresponding to an optimal superstring {\tt ccaeaeaecc}. (b)~A~solution of length~11 constructed by GHA.}
%\label{fig:tough}
%\end{figure}

\newcommand{\ged}[2]{
\tikzstyle{t}=[vertex,draw=black]
\tikzstyle{p}=[->,decorate,decoration=snake,bend left=10]
\begin{scope}[yshift=#1mm]
\node[inputvertex] (ccaen) at (0,5) {{\tt cc}({\tt ae})$^n$};
\node[inputvertex] (eann) at (10,5) {({\tt ea})$^{n+1}$};
\node[inputvertex] (aencc) at (4.5,5) {({\tt ae})$^n${\tt cc}};
\node[t] (ccaena) at (-1,4) {\tt cc(ae)$^{n-1}$a};
\node[t] (caen) at (1.5,4) {\tt c(ae)$^{n}$};
\node[t] (eane) at (9,4) {\tt (ea)$^{n}$e};
\node[t] (aean) at (11,4) {\tt a(ea)$^{n}$};
\node[t] (aenc) at (3.5,4) {\tt (ae)$^{n}$c};
\node[t] (eaencc) at (6,4) {\tt e(ae)$^{n-1}$cc};
\node[t] (ccaenn) at (1,3) {\tt cc(ae)$^{n-1}$};
\node[t] (aen) at (3.5,3) {\tt (ae)$^{n}$};
\node[t] (ean) at (10,3) {\tt (ea)$^{n}$};
\node[t] (aenncc) at (6,3) {\tt (ae)$^{n-1}$cc};
\node[t] (eaenn) at (3.5,2) {\tt e(ae)$^{n-1}$};
\node[t] (aeann) at (7,2) {\tt a(ea)$^{n-1}$};
\node[t] (eps) at (5,0) {$\varepsilon$};

\foreach \f/\t in {ccaena/ccaen, ccaen/caen, eane/eann, eann/aean, aenc/aencc, aencc/eaencc, ccaenn/ccaena, caen/aen, ean/eane, aean/ean, aen/aenc, eaencc/aenncc, ean/aeann, eaenn/ean}
  \draw[->] (\f) -- (\t);
  
\path (eps) edge[p] (ccaenn);
\path (aenncc) edge[p] (eps);

#2
\end{scope}
}

 
\begin{figure}
\begin{mypic}
\ged{0}{
\foreach \f/\t in {aeann/aen, aen/eaenn}
  \draw[->] (\f) -- (\t);
}

\ged{-60}{
\path (eps) edge[p] (eaenn);
\path (aeann) edge[p] (eps);
}
\end{mypic}
\caption{Top: optimal solution for the dataset $\{ {\tt cc}({\tt ae})^n, ({\tt ea})^{n+1}, ({\tt ae})^n{\tt cc} \}$. Bottom: solution constructed by GHA.}
\label{fig:tough}
\end{figure}

\section{Collapsing Algorithm}
In this section, we introduce another conjecture that
we call Collapsing Superstring Conjecture. It implies immediately the Greedy Hierarchical Superstring Conjecture. Moreover, it is based on an~alternative simple algorithm in the hierarchical graph. If the conjecture is true, then this algorithm is also 2-approximate. We have verified the conjecture on various datasets. In Subsec.~\ref{subsec:scs3} we support it by proving its special case for strings of length~3.

\subsection{Algorithm and Conjecture}
The idea is the algorithm is the following. 
We start with any solution~$D$ in the hierarchical graph. 
We double every edge of~$D$ (note that $D$ remains to be a~solution). What we do next can be informally described as follows:
\begin{enumerate}
\item Imagine that the edges of~$D$ constitute a~circular thread and that there is a~nail in every node~$s \in {\cal S}$.
\item We apply gravitation to the thread, i.e., we replace every pair of edges $(\pref(v), v)$, $(v, \suff(v))$ 
with a~pair $(v, \pref(\suff(v)))$, $(\pref(\suff(v)), \suff(v))$, where $a$ and $b$ are symbols and $s$ is a~string. We call this {\em collapsing}, see Fig.~\ref{fig:collapsing}.
\end{enumerate}
Formally, after doubling every edge of~$D$, we start processing the nodes of the hierarchical graph level by level in the ascending order and in the lexicographic order on every level. If for the current node~$v$ there is a~pair if edges $(\pref(v), v), (v, \suff(v)) \in D$, we replace it by a~pair of edges $(\pref(v), \pref(\suff(v))), (\pref(\suff(v)))$ if $D$~remains to be a~solution (i.e., it is still connected). There is one exception for this: if $|v|=1$, then $\pref(\suff(v))$ is undefined and we just remove the pair of edges. 
A~formal pseudocode of this collapsing procedure is given in Algorithm~\ref{alg:collapse}. This way, the algorithm lifts down all edges of the doubled set~$D$ that are not needed for connectivity. See Algorithm~\ref{alg:ca} for a~formal pseudocode.

\begin{figure}[ht]
\begin{mypic}
\begin{scope}[minimum size=6mm]
%\draw[help lines] (0,0) grid (14,3);
\node[vertex] (a) at (0, 1.5) {$\pref(v)$};
\node[vertex,inner sep=1mm] (b) at (1.5, 2.5) {$v$};
\node[vertex] (c) at (3, 1.5) {$\suff(v)$};
\node[vertex] (d) at (1.5, 0.5) {$ \pref(\suff(v))$};
\draw[->,dashed] (a) -- (b);
\draw[->,dashed] (b) -- (c);
\draw[->] (a) -- (d);
\draw[->] (d) -- (c);

\begin{scope}[xshift=80mm]
\node[vertex] (a) at (0, 1.5) {\tt aba};
\node[vertex,inner sep=1mm] (b) at (1.5, 2.5) {\tt abac};
\node[vertex] (c) at (3, 1.5) {\tt bac};
\node[vertex] (d) at (1.5, 0.5) {\tt ba};
\draw[->,dashed] (a) -- (b);
\draw[->,dashed] (b) -- (c);
\draw[->] (a) -- (d);
\draw[->] (d) -- (c);
\end{scope}
\end{scope}
\end{mypic}
\caption{Collapsing a~pair of edges is replacing a~pair of dashed edges with a~pair of solid edges: general case (left) and example (right). A~``physical'' meaning of this transformation is that to get {\tt bac} from {\tt aba} one needs to cut~{\tt a} from the beginning and append~{\tt c} to the end and these two operations commute.}
\label{fig:collapsing}
\end{figure}

\begin{algorithm}[ht]
\caption{Collapse}\label{alg:collapse}
\hspace*{\algorithmicindent} \textbf{Input:} hierarchical graph $HG(V,E)$, solution $D$, node $v \in V$.
%\hspace*{\algorithmicindent} \textbf{Output:} a~superstring of~${\cal S}$ as a~path $D$~in the hierarchical graph.
\begin{algorithmic}[1]
\If{$(\pref(v), v), (v, \suff(v)) \in D$}
\State $D \gets D \setminus \{(\pref(v), v), (v, \suff(v))\}$
\If{$|v| > 1$}
\State $D \gets D \cup \{(\pref(v), \pref(\suff(v))), (\pref(\suff(v)), \suff(v))\}$
\EndIf
\EndIf
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[ht]
\caption{Collapsing Algorithm (CA)}
\label{alg:ca}
\hspace*{\algorithmicindent} \textbf{Input:} hierarchical graph $HG(V,E)$, solution $D$.\\
\hspace*{\algorithmicindent} \textbf{Output:} (possibly) shortened solution.
% a~superstring of~${\cal S}$ as a~path $D$~in the hierarchical graph.
\begin{algorithmic}[1]
\For{level~$l$ in $HG$ in descending order}
\For{all $v \in V(HG)$ s.t. $|v|=\text{\textsl{level}}$ in lexicographic order:}
\While{$(\pref(v), v), (v, \suff(v)) \in D$ and collapsing it does not make~$D$ disconnected}
\State $\text{\sc Collapse}(HG(V,E), D, v)$
\EndWhile
\EndFor
\EndFor
\State return $D$
\end{algorithmic}
\end{algorithm}

When $l>1$, the collapsing procedure does not change the total length of~$D$. 
What one normally sees at the beginning of the
$l=1$ iteration is a~solution with many 
redundant pairs of edges of the form $(a, \varepsilon)$, $(\varepsilon, a)$. It is exactly this stage of the algorithm where the total length of~$D$ is decreased by the collapsing procedure. See Figures~\ref{fig:coll} and~\ref{fig:collnaive} give examples of applying the Collapsing Algorithms for the cases when~$D$ is an optimal and naive solution respectively.

\begin{figure}[ht]
\begin{mypic}
\we{0}{0}{a}{
\foreach \f/\t/\a in {eps/a/10, eps/a/20, 
a/aa/10, a/aa/20, 
aa/aaa/10, aa/aaa/20,
aaa/aa/10, aaa/aa/20,
aa/a/10, aa/a/20, 
a/ae/0, a/ae/10,
ae/aec/0, ae/aec/10,
aec/ec/0, aec/ec/10,
ec/c/0, ec/c/10,
c/ca/0, c/ca/10,
ca/cae/0, ca/cae/10,
cae/ae/0, cae/ae/10,
ae/e/0, ae/e/10,
e/ee/10, e/ee/20,
ee/eee/10, ee/eee/20,
eee/ee/10, eee/ee/20,
ee/e/10, ee/e/20,
e/eps/10, e/eps/20}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{57}{0}{b}{
\foreach \f/\t/\a in {eps/a/10, eps/a/20, 
a/aa/10, a/aa/20, a/aa/30, aa/a/30,
aa/aaa/10,
aaa/aa/10,
aa/a/10, aa/a/20, 
a/ae/0, a/ae/10,
ae/aec/0, ae/e/20,
aec/ec/0, e/ec/0,
ec/c/0, ec/c/10,
c/ca/0, c/ca/10,
ca/cae/0, ca/a/0, a/ae/20,
cae/ae/0,
ae/e/0, ae/e/10,
e/ee/10, e/ee/20, e/ee/30,
ee/eee/10,
eee/ee/10,
ee/e/10, ee/e/20, ee/e/30,
e/ee/30,
e/eps/10, e/eps/20}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{114}{0}{c}{
\foreach \f/\t/\a in {
eps/a/10, eps/a/20, eps/a/30, eps/a/40, a/eps/10, a/eps/20,
a/aa/10,
aa/aaa/10,
aaa/aa/10,
aa/a/10, 
a/ae/0, a/ae/10,
ae/aec/0, ae/e/20,
aec/ec/0, e/ec/0,
ec/c/0, ec/c/10,
c/ca/0, c/ca/10,
ca/cae/0, ca/a/0, a/ae/20,
cae/ae/0,
ae/e/0, ae/e/10,
e/ee/10, e/ee/20, e/ee/30,
ee/eee/10,
eee/ee/10,
ee/e/10, 
ee/e/20,
ee/e/30,
e/ee/30,
e/eps/10, e/eps/20}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{0}{-55}{d}{
\foreach \f/\t/\a in {
eps/a/10, eps/a/20, eps/a/30, eps/a/40, 
a/eps/10, a/eps/20, a/eps/30, a/eps/40, a/eps/50,
a/aa/10,
aa/aaa/10,
aaa/aa/10,
aa/a/10, 
ae/aec/0,
aec/ec/0, e/ec/0,
ec/c/0, ec/c/10,
c/ca/0, c/ca/10,
ca/cae/0, ca/a/0,
cae/ae/0,
e/ee/10, e/ee/20, e/ee/30,
ee/eee/10,
eee/ee/10,
ee/e/10, ee/e/20, ee/e/30,
e/ee/30,
e/eps/10, e/eps/20, e/eps/30,
eps/e/10, eps/e/20, eps/e/30}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{57}{-55}{e}{
\foreach \f/\t/\a in {
eps/a/10, eps/a/20, eps/a/30, eps/a/40, eps/a/50,
a/eps/10, a/eps/20, a/eps/30, a/eps/40, a/eps/50,
a/aa/10,
aa/aaa/10,
aaa/aa/10,
aa/a/10, 
ae/aec/0,
aec/ec/0, e/ec/0,
ec/c/0, ec/c/10,
c/ca/0,
ca/cae/0,
cae/ae/0,
e/ee/10, e/ee/20, e/ee/30,
ee/eee/10,
eee/ee/10,
ee/e/10, ee/e/20, ee/e/30,
e/ee/30,
e/eps/10, e/eps/20, e/eps/30,
eps/e/10, eps/e/20, eps/e/30,
c/eps/10}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{114}{-55}{f}{
\foreach \f/\t/\a in {
eps/a/10, eps/a/20, eps/a/30, eps/a/40, eps/a/50,
a/eps/10, a/eps/20, a/eps/30, a/eps/40, a/eps/50,
a/aa/10,
aa/aaa/10,
aaa/aa/10,
aa/a/10, 
ae/aec/0,
aec/ec/0,
ec/c/0,
c/ca/0,
ca/cae/0,
cae/ae/0,
e/ee/10, e/ee/20, e/ee/30,
ee/eee/10,
eee/ee/10,
ee/e/10, ee/e/20, ee/e/30,
e/ee/30,
e/eps/10, e/eps/20, e/eps/30, e/eps/40,
eps/e/10, eps/e/20, eps/e/30,
c/eps/10, eps/c/10}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{0}{-110}{g}{
\foreach \f/\t/\a in {aa/aaa/10, aaa/aa/10, ca/cae/0, cae/ae/0, ae/aec/0, aec/ec/0, ee/eee/10, eee/ee/10, aa/a/10, a/aa/10, c/ca/0, ec/c/0, ee/e/10, e/ee/10, a/aa/10, aa/a/10, eps/c/10, c/eps/10, 
e/eps/10, eps/e/10, 
e/eps/20, eps/e/20,
e/eps/30, eps/e/30,
e/eps/40, eps/e/40,
e/eps/50, eps/e/50,
a/eps/10, eps/a/10,
a/eps/20, eps/a/20,
a/eps/30, eps/a/30,
a/eps/40, eps/a/40,
a/eps/50, eps/a/50}
\path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{57}{-110}{h}{
\foreach \f/\t/\a in {aa/aaa/10, aaa/aa/10, ca/cae/0, cae/ae/0, ae/aec/0, aec/ec/0, ee/eee/10, eee/ee/10, aa/a/10, a/aa/10, c/ca/0, ec/c/0, ee/e/10, e/ee/10, a/aa/10, aa/a/10, eps/c/10, c/eps/10, 
e/eps/10, eps/e/10, 
a/eps/10, eps/a/10}
\path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\end{mypic}
\caption{Stages of applying the Collapsing Algorithm to the dataset $\{{\tt aaa}, {\tt cae}, {\tt aec}, {\tt eee}\}$ and its \textbf{optimal} solution. (a)~We start by doubling every edge of the optimal solution from Figure~\ref{fig:hgex}(c). 
(b)~After collapsing all nodes at level $l=3$. 
(c)~After processing the node {\tt aa} at level $l=2$. Note that the algorithm leaves a~pair of edges $({\tt a}, {\tt aa}), ({\tt aa}, {\tt a})$ as they are needed to connect the component $\{{\tt aa}, {\tt aaa}\}$ to the rest of the solution. (d)~After processing the {\tt ae} node. The algorithm collapses all pairs of edges for this node as it lies in the same component as a~node~{\tt c}. 
(e)~After processing the {\tt ca} node.
(f)~After processing the {\tt ec} node.
(g)~After processing the {\tt ee} node. Note that at this point the solution has exactly the same length as at the very beginning (at stage~(a)).
(h)~Finally, after collapsing all the unnecessary pairs of edges from the level~$l=1$. The resulting solution is the same as constructed by the Greedy Hierarchical Algorithm (Figure~\ref{fig:hgexa}(c)).}
\label{fig:coll}
\end{figure}

\begin{figure}[ht]
\begin{mypic}
\we{0}{0}{a}{
\foreach \f/\t/\a in {
eps/a/10,
a/aa/10,
aa/aaa/10,
aaa/aa/10,
aa/a/10,
a/eps/10,
eps/c/10,
c/ca/0,
ca/cae/0,
cae/ae/0,
ae/aec/0,
aec/ec/0,
ec/c/0,
c/eps/10,
eps/e/10,
e/ee/10,
ee/eee/10,
eee/ee/10,
ee/e/10,
e/eps/10
}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{57}{0}{b}{
\foreach \f/\t/\a in {
eps/a/10, eps/a/20,
a/aa/10, a/aa/20,
aa/aaa/10, aa/aaa/20,
aaa/aa/10, aaa/aa/20,
aa/a/10, aa/a/20,
a/eps/10, a/eps/20,
eps/c/10, eps/c/20,
c/ca/0, c/ca/10,
ca/cae/0, ca/cae/10,
cae/ae/0, cae/ae/10,
ae/aec/0, ae/aec/10,
aec/ec/0, aec/ec/10,
ec/c/0, ec/c/10,
c/eps/10, c/eps/20,
eps/e/10, eps/e/20,
e/ee/10, e/ee/20,
ee/eee/10, ee/eee/20,
eee/ee/10, eee/ee/20,
ee/e/10, ee/e/20,
e/eps/10, e/eps/20
}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{114}{0}{c}{
\foreach \f/\t/\a in {
eps/a/10, eps/a/20,
a/aa/10, a/aa/20, a/aa/30,
aa/aaa/10,
aaa/aa/10,
aa/a/10, aa/a/20, aa/a/30,
a/eps/10, a/eps/20,
eps/c/10, eps/c/20,
c/ca/0, c/ca/10,
ca/cae/0, ca/a/0,
cae/ae/0, a/ae/0,
ae/aec/0, ae/e/0,
aec/ec/0, e/ec/0,
ec/c/0, ec/c/10,
c/eps/10, c/eps/20,
eps/e/10, eps/e/20,
e/ee/10, e/ee/20,
ee/eee/10, ee/e/30,
eee/ee/10, e/ee/30,
ee/e/10, ee/e/20,
e/eps/10, e/eps/20
}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{0}{-55}{d}{
\foreach \f/\t/\a in {
eps/a/10, eps/a/20, eps/a/30, eps/a/40, eps/a/50,
a/aa/10,
aa/aaa/10,
aaa/aa/10,
aa/a/10,
a/eps/10, a/eps/20, a/eps/30, a/eps/40, a/eps/50,
eps/c/10, eps/c/20, eps/c/30,
c/ca/0,
ca/cae/0,
cae/ae/0,
ae/aec/0,
aec/ec/0,
ec/c/0,
c/eps/10, c/eps/20, c/eps/30,
eps/e/10, eps/e/20, eps/e/30, eps/e/40, eps/e/50,
e/ee/10, 
ee/eee/10, 
eee/ee/10, 
ee/e/10, 
e/eps/10, e/eps/20, e/eps/30, e/eps/40, e/eps/50
}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{57}{-55}{e}{
\foreach \f/\t/\a in {
eps/a/10, 
a/aa/10,
aa/aaa/10,
aaa/aa/10,
aa/a/10,
a/eps/10, 
eps/c/10, 
c/ca/0,
ca/cae/0,
cae/ae/0,
ae/aec/0,
aec/ec/0,
ec/c/0,
c/eps/10, 
eps/e/10, 
e/ee/10, 
ee/eee/10, 
eee/ee/10, 
ee/e/10, 
e/eps/10
}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}


\end{mypic}
\caption{Stages of applying the Collapsing Algorithm to the dataset $\{{\tt aaa}, {\tt cae}, {\tt aec}, {\tt eee}\}$ and its \textbf{naive} solution resulting from overlapping the input strings in the same order they are given. (a)~The solution of length 10 corresponding to the superstring {\tt aaacaeceee}. (b)~The doubled solution. (c)~After collapsing the $l=3$ level. (d)~After collapsing the $l=2$ level. (e)~After collapsing the $l=1$ level. }
\label{fig:collnaive}
\end{figure}

\todo[inline]{Sasha, state the conjecture}




\subsection{Proof of the Special Case: Strings of Length~3}\label{subsec:scs3}
%\input specialcase


\section{Further Directions and Open Problems}
The natural open problem is to prove the Collapsing Superstring Conjecture.
It would also be interesting to find other applications of the 
hierarchical graphs. We list two such potential applications below.
\begin{description}
\item[Genome assembly.] As we illustrated, the hierarchical graph in a~sense
generalizes de Bruijn graph. The latter one is used heavily 
in genome assembly~\cite{pevzner2001eulerian}.
Can one adopt the hierarchical graph for this task? For this, one
would need to come up with a~compact representation of the graph
(as datasets in genome assembly are massive) as well as with a~way of
handling errors in the input data.

\item[Exact algorithms.] Can one use hierarchical graphs to solve SCS exactly in time $(2-\varepsilon)^n$?
\todo[inline]{Sasha, tell more about it}
The SCS problem is a special case of the Traveling Salesman problem. Indeed, one can consider the \emph{prefix graph} where each vertex corresponds to an input string, and every pair $(s_i, s_j)$ of vertices is connected by an arc of weight $|\prefix(s_i, s_j)|$, that is, the length of .... 
\end{description}

\bibliographystyle{alpha}
\bibliography{main}

\end{document}